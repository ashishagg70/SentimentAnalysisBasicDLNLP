{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from collections import defaultdict\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "max_len=30\n",
    "NUMBER_CLASSES = 5\n",
    "EMBDIM=300\n",
    "hidden_layer_count=1\n",
    "hidden_layer_numunits=[128]\n",
    "embedding_file=''\n",
    "activation_name='relu'\n",
    "# vocab = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = defaultdict(int)\n",
    "embeddings = {}#defaultdict(lambda:np.zeros((50,)))\n",
    "f=open(embedding_file, 'r')\n",
    "lines=f.readlines()\n",
    "idx=1\n",
    "\n",
    "for line in lines:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vector = np.asarray(values[1:], \"float32\")\n",
    "    embeddings[word] = vector\n",
    "    word_to_index[word]=idx\n",
    "    idx=idx+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len=len(word_to_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_lower(text):\n",
    "    return [i.lower() for i in text]\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return [i.translate(str.maketrans(dict.fromkeys(string.punctuation))) for i in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(text):\n",
    "    \n",
    "    m=len(text)\n",
    "    text_encoded = np.zeros((m,max_len))\n",
    "    for i in range(m):\n",
    "        sentence_words =text[i]\n",
    "        j = 0\n",
    "        for w in sentence_words:\n",
    "            text_encoded[i, j] = word_to_index.get(w)\n",
    "            j = j + 1\n",
    "\n",
    "            \n",
    "    return text_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    newtext = []\n",
    "    f=open('stopwords.txt','r')\n",
    "    stopwordList=f.readlines()\n",
    "#     stopwordList = (stopwords.words('english'))\n",
    "#     stopwordList=set(remove_punctuation(stopwordList))\n",
    "    #print('-----', stopwordList, '---------')\n",
    "    for tokens in text:\n",
    "        newtext.append([w for w in tokens if not w in stopwordList])\n",
    "    #print(newtext[0])\n",
    "    return newtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_tokenization(text):\n",
    "    return [word_tokenize(i) for i in text]\n",
    "\n",
    "def perform_padding(data):\n",
    "    pass\n",
    "#     return [list(np.pad(sent, (0, MAX_SENTENCE_LENGTH - len(sent)), 'constant', constant_values='0')) for sent in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, isTrain=True):\n",
    "    review = data[\"reviews\"]\n",
    "    review = convert_to_lower(review)\n",
    "    review = remove_punctuation(review)\n",
    "    review = perform_tokenization(review)\n",
    "    review = remove_stopwords(review)\n",
    "    review = encode_data(review)\n",
    "    #review = perform_padding(review)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_layer():\n",
    "    \n",
    "    vocab_size = len(word_to_index) + 1           \n",
    "    emb_dim = EMBDIM\n",
    "    emb_matrix = np.zeros((vocab_len,emb_dim))\n",
    "    for word, idx in word_to_index.items():\n",
    "        emb_matrix[idx, :] = embeddings[word]\n",
    "\n",
    "    embedding_layer = tf.keras.layers.Embedding(input_dim=vocab_len,output_dim=emb_dim,weights=[emb_matrix],input_length=max_len,trainable=True)\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_activation(x):\n",
    "    expX = K.exp(x-K.reshape(K.max(x, axis=1), (K.shape(x)[0], 1)))\n",
    "    s = K.reshape(K.sum(expX, axis=1), (K.shape(x)[0], 1))\n",
    "    return expX / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "\n",
    "    def __init__(self, reviews, ratings):\n",
    "        self.reviews = np.array(reviews, dtype='float32')\n",
    "        self.ratings = tf.keras.utils.to_categorical(y=ratings,num_classes=NUMBER_CLASSES)\n",
    "        self.model = None\n",
    "\n",
    "    def build_nn(self):\n",
    "        \n",
    "        sentence_indices = tf.keras.layers.Input(shape=(max_len,),dtype='int32')\n",
    "        embedding = embedding_layer()\n",
    "        X=embedding(sentence_indices)\n",
    "        X = tf.keras.layers.Flatten()(X)\n",
    "        for i in range(hidden_layer_count):\n",
    "            X = tf.keras.layers.Dense(units=hidden_layer_numunits[i],kernel_initializer='glorot_uniform')(X)\n",
    "            X=tf.keras.layers.Activation(activation=activation_name)(X)\n",
    "        \n",
    "        X = tf.keras.layers.Dense(units=5,activation='softmax')(X)\n",
    "        \n",
    "        self.model = tf.keras.Model(inputs=sentence_indices,outputs=X)\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "        self.model.summary()\n",
    "        \n",
    "#         featureDim = self.reviews.shape[1]\n",
    "#         self.model = tf.keras.Sequential()\n",
    "#         self.model.add(tf.keras.layers.Dense(NUMBER_CLASSES, activation=softmax_activation, input_shape=(featureDim,)))\n",
    "#         self.model.summary()\n",
    "#         lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-3,decay_steps=10000,decay_rate=0.9)\n",
    "#         self.model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "#                            metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "    def train_nn(self, batch_size, epochs):\n",
    "        es = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1,patience=10)\n",
    "        self.model.fit(self.reviews, self.ratings, epochs=epochs, batch_size=batch_size,validation_split=0.2,shuffle=1,callbacks=[es])\n",
    "\n",
    "    def predict(self, reviews):\n",
    "        reviews = np.array(reviews, dtype='float32')\n",
    "        return np.argmax(self.model.predict(reviews), axis=1) + 1\n",
    "    \n",
    "    def predictWithPr(self, reviews):\n",
    "        reviews = np.array(reviews, dtype='float32')\n",
    "        return self.model.predict(reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings = np.array(train_data[\"ratings\"])\n",
    "train_ratings=train_ratings-1\n",
    "train_reviews = preprocess_data(train_data)\n",
    "test_reviews = preprocess_data(test_data, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        [(None, 30)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_20 (Embedding)     (None, 30, 300)           120000300 \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 9000)              0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 128)               1152128   \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 121,153,073\n",
      "Trainable params: 121,153,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNet(train_reviews, train_ratings)\n",
    "model.build_nn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, epochs = 256, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - 137s 871ms/step - loss: 1.0997 - accuracy: 0.6325 - val_loss: 1.0583 - val_accuracy: 0.5890\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - 136s 869ms/step - loss: 0.7945 - accuracy: 0.7083 - val_loss: 0.9680 - val_accuracy: 0.6292\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - 138s 878ms/step - loss: 0.6893 - accuracy: 0.7497 - val_loss: 0.9270 - val_accuracy: 0.6491\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - 139s 883ms/step - loss: 0.6075 - accuracy: 0.7833 - val_loss: 0.9100 - val_accuracy: 0.6552\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - 139s 884ms/step - loss: 0.5589 - accuracy: 0.8033 - val_loss: 0.9106 - val_accuracy: 0.6577\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - 141s 901ms/step - loss: 0.4985 - accuracy: 0.8281 - val_loss: 0.9022 - val_accuracy: 0.6601\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - 144s 916ms/step - loss: 0.4537 - accuracy: 0.8497 - val_loss: 0.9034 - val_accuracy: 0.6634\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - 141s 898ms/step - loss: 0.4075 - accuracy: 0.8715 - val_loss: 0.9125 - val_accuracy: 0.6600\n",
      "Epoch 9/100\n",
      " 51/157 [========>.....................] - ETA: 1:35 - loss: 0.3696 - accuracy: 0.8896"
     ]
    }
   ],
   "source": [
    "model.train_nn(batch_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Train data evaluation metrices==========================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.79      0.81      4059\n",
      "           2       0.82      0.61      0.70      2265\n",
      "           3       0.80      0.68      0.73      3612\n",
      "           4       0.86      0.68      0.76      6871\n",
      "           5       0.91      0.98      0.94     33193\n",
      "\n",
      "    accuracy                           0.89     50000\n",
      "   macro avg       0.84      0.75      0.79     50000\n",
      "weighted avg       0.88      0.89      0.88     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print(\"=================Train data evaluation metrices==========================\")\n",
    "# evaluation_matrices(train_ratings, model.predict(train_reviews))\n",
    "\n",
    "\n",
    "print(classification_report(train_ratings+1,model.predict(train_reviews)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================Test data evaluation metrices==========================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.48      0.53      1271\n",
      "           2       0.24      0.12      0.16       630\n",
      "           3       0.29      0.22      0.25       911\n",
      "           4       0.29      0.15      0.20      1404\n",
      "           5       0.73      0.91      0.81      5784\n",
      "\n",
      "    accuracy                           0.64     10000\n",
      "   macro avg       0.43      0.38      0.39     10000\n",
      "weighted avg       0.58      0.64      0.60     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=================Test data evaluation metrices==========================\")\n",
    "\n",
    "\n",
    "\n",
    "testPredictions = model.predict(test_reviews)\n",
    "test_ground_truth = np.array(pd.read_csv('gold_test.csv')['ratings'])\n",
    "\n",
    "# evaluation_matrices(test_ground_truth, testPredictions)\n",
    "\n",
    "print(classification_report(test_ground_truth, testPredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.3200071e-05 3.8046779e-05 4.3965574e-05 3.1264510e-03 9.9674833e-01]\n",
      " [3.1599912e-01 7.6396711e-02 8.7443165e-02 8.5956931e-02 4.3420410e-01]]\n"
     ]
    }
   ],
   "source": [
    "ip_data = pd.read_csv(\"input.csv\")\n",
    "ip_reviews = preprocess_data(ip_data, False)\n",
    "pred = model.predictWithPr(ip_reviews)\n",
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviews</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Amazing!! I love and swear by this stuff. A mu...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>This product came in pieces .... would NOT rec...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            reviews  rating\n",
       "0           0  Amazing!! I love and swear by this stuff. A mu...       5\n",
       "1           1  This product came in pieces .... would NOT rec...       5"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip_data[\"rating\"]=np.argmax(pred, axis=1) + 1\n",
    "ip_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    1       0.65      0.54      0.59      4059\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "without_hidden_layer(Glove_300d):\n",
    "\n",
    "=================Train data evaluation metrices==========================\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.65      0.54      0.59      4059\n",
    "           2       0.54      0.17      0.25      2265\n",
    "           3       0.52      0.25      0.34      3612\n",
    "           4       0.55      0.19      0.28      6871\n",
    "           5       0.76      0.96      0.85     33193\n",
    "\n",
    "    accuracy                           0.74     50000\n",
    "   macro avg       0.61      0.42      0.46     50000\n",
    "weighted avg       0.70      0.74      0.69     50000\n",
    "\n",
    "\n",
    "=================Test data evaluation metrices==========================\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           1       0.60      0.43      0.50      1271\n",
    "           2       0.22      0.06      0.09       630\n",
    "           3       0.30      0.15      0.20       911\n",
    "           4       0.27      0.08      0.12      1404\n",
    "           5       0.68      0.94      0.79      5784\n",
    "\n",
    "    accuracy                           0.63     10000\n",
    "   macro avg       0.41      0.33      0.34     10000\n",
    "weighted avg       0.55      0.63      0.56     10000\n",
    "\n",
    "loss: 0.6703 - accuracy: 0.7599 - val_loss: 1.0118 - val_accuracy: 0.6307\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
